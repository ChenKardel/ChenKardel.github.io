<!DOCTYPE html>
<html lang="z">
<head>
    <meta charset="utf-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    
    <title>神经网络实践经验(1) | Kardel的希尔伯特空间</title>
    <meta name="renderer" content="webkit">
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="320">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

    <meta name="description" content="浅度辍学集大成者
the man who masters shallow dropout">

    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="神经网络实践经验(1) | Kardel的希尔伯特空间">
    <meta name="twitter:description" content="浅度辍学集大成者
the man who masters shallow dropout">

    <meta property="og:type" content="article">
    <meta property="og:title" content="神经网络实践经验(1) | Kardel的希尔伯特空间">
    <meta property="og:description" content="浅度辍学集大成者
the man who masters shallow dropout">

    
    <meta name="author" content="kardel">
    
    <link rel="stylesheet" href="/css/vno.css">
    <link rel="stylesheet" href="//netdna.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css">

    
    <link rel="icon" href="/images/avatar-icon.png">
    

    <meta name="generator" content="hexo"/>
    
    <link rel="alternate" type="application/rss+xml" title="Kardel的希尔伯特空间" href="/atom.xml">
    

    <link rel="canonical" href="http://ChenKardel.github.io/2018/06/02/神经网络实践经验-1/"/>

                 
</head>

<body class="home-template no-js">
    <script src="//cdn.bootcss.com/jquery/2.1.4/jquery.min.js"></script>
    <script src="/js/main.js"></script>
    <span class="mobile btn-mobile-menu">
        <i class="fa fa-list btn-mobile-menu__icon"></i>
        <i class="fa fa-angle-up btn-mobile-close__icon hidden"></i>
    </span>

    
<header class="panel-cover panel-cover--collapsed" style="background-image: url(/images/background-cover.jpg)">
  <div class="panel-main">
    <div class="panel-main__inner panel-inverted">
    <div class="panel-main__content">

        <a href="/" title="前往 Kardel的希尔伯特空间 的主页"><img src="/images/avatar.jpg" width="80" alt="Kardel的希尔伯特空间 logo" class="panel-cover__logo logo" /></a>
        <h1 class="panel-cover__title panel-title"><a href="/" title="link to homepage for Kardel的希尔伯特空间">Kardel的希尔伯特空间</a></h1>
        
        <hr class="panel-cover__divider" />
        <p class="panel-cover__description">浅度辍学集大成者
the man who masters shallow dropout
</p>
        <hr class="panel-cover__divider panel-cover__divider--secondary" />

        <div class="navigation-wrapper">
          <div>
          <nav class="cover-navigation cover-navigation--primary">
            <ul class="navigation">
              <li class="navigation__item"><a href="/#blog" title="Visit the blog" class="blog-button">Blog</a></li>
            
              <li class="navigation__item"><a href="/aboutme">关于我</a></li>
            
            </ul>
          </nav>
          </div>
          <div>
          <nav class="cover-navigation navigation--social">
  <ul class="navigation">

  <!-- Weibo-->
  

  <!-- Github -->
  
  <li class="navigation__item">
    <a href="https://github.com/ChenKardel" title="GitHub" target="_blank">
      <i class='social fa fa-github'></i>
      <span class="label">Github</span>
    </a>
  </li>


<!-- Stack Overflow -->
        

  <!-- Google Plus -->
  

<!-- Facebook -->

  
<!-- Twitter -->

  

  <li class="navigation__item">
    <a href="/atom.xml" title="RSS" target="_blank">
      <i class='social fa fa-rss'></i>
      <span class="label">RSS</span>
    </a>
  </li>



  </ul>
</nav>

          </div>
        </div>

      </div>

    </div>

    <div class="panel-cover--overlay cover-purple"></div>
  </div> 
</header>

    <div class="content-wrapper">
        <div class="content-wrapper__inner">
            <article class="post-container post-container--single">

  <header class="post-header">
    <div class="post-meta">
      <time datetime="2018-06-02T08:54:58.000Z" class="post-list__meta--date date">2018-06-02</time> &#8226; <span class="post-meta__tags tags">于 
  <a class="tag-link" href="/tags/深度学习/">深度学习</a>, <a class="tag-link" href="/tags/神经网络实践经验/">神经网络实践经验</a>
 </span>
      <span class="page-pv">
       Read <span id="busuanzi_value_page_pv"><i class="fa fa-spinner fa-spin"></i></span>
      </span> 
   
    </div>
    <h1 class="post-title">神经网络实践经验(1)</h1>
  </header>

  <section class="post">
    <h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>本系列是本人记录在自己实践中遇到的很多读死书无法学习到的经验，不完全脱离理论，甚至说是超过理论之外的东西。</p>
<p>本人水平很差（深度学习之耻），有些说的简陋的东西也当是献丑了。</p>
<h4 id="1-神经网络的输入最好有一定相关性，否则很容易产生过拟合的效果"><a href="#1-神经网络的输入最好有一定相关性，否则很容易产生过拟合的效果" class="headerlink" title="1. 神经网络的输入最好有一定相关性，否则很容易产生过拟合的效果"></a>1. 神经网络的输入最好有一定相关性，否则很容易产生过拟合的效果</h4><p>所谓的过拟合，就是模型学习到本应该学习到的特征之外的特征。</p>
<p><img src="/2018/06/02/神经网络实践经验-1/image1.bmp" alt="图一"></p>
<p>如图，本来模型只应该学习到x，$x^2$ 和常数项的特征，但是由于模型的容量（capacity）太大，模型学习到了$x^3$ 和$x^4$的特征。所以造成最后模型的扭曲。</p>
<p>过拟合的问题大家肯定都懂，模型在testing数据集和training数据集的差异会非常大，在training集上表现非常好的数据在testing集上会非常差。</p>
<p><img src="/2018/06/02/神经网络实践经验-1/image2.bmp" alt="图二"></p>
<p>在神经网络中最常用的正则化方法是Dropout。</p>
<p>同时我们应该去了解一下神经网络中的全连接层。全连接层在数据于数据之中找关系，提取输入数据的浅层特征与深层特征并且将这些特征映射到类别中（此处我只说的是多分类，其他的工作暂时不讲）。也就是说在全连接层中它寻找的输入每个神经元与神经元之间的联系。</p>
<p>从某种意义上来说，神经网络就是个高超的特征工程器。</p>
<p>在某些时候，我们为了去做多分类，会去试着去找无关（前置知识）的特征然后作为输入扔给神经网络。甚至是两个相互无关（前置知识）的向量拼接之后扔给神经网络。</p>
<p>不得不说，这是非常蠢的想法。</p>
<p>我们迫使神经网络去找到已知无关的数据的联系特征，这本身就可能然神经网络产生过拟合。</p>
<p>就比如，我现在用多层感知机(MLP)做推荐系统，有user向量<strong>u</strong>也有item向量<strong>i</strong> ，user和item没有直接关联，我们将<strong>u</strong>与<strong>i</strong>拼接并直接扔给MLP。MLP学习到了user的特征还有item的特征，还有……user中某个神经元和item某个神经元的联系。</p>
<p>单单用脑子想想就知道，我们会学习到很多在推荐系统中一点用都没有的特征，相当于神经网络瞎做特征工程，然后过拟合了，即时加了Dropout也没用。</p>
<p>为什么使用神经网络去处理图像的效果好？因为本身图像就是一个上下文相关的数据，很多像素点的集合不叫有意义的图像，像素点与像素点连接所构成的有意义的数据才能叫有意义的图像。但是图像本身是局部相关，我左下角的像素点可能和右上角的像素点一点关系都没有，但是左下角的像素点只与它周围一圈的像素点有关，所以CNN较MLP更适合Computer Vision。</p>
<p>NLP同理（虽然我不懂XD）。</p>
<p>这个时候我们应该做什么呢？</p>
<p>本人认为，应该试着使用CNN这种局部特征网络。并且可以试着在<strong>u</strong>和<strong>i</strong>拼接处加上少许的0（数量大概是filter的大小减一），这样可以杜绝overfit</p>
<p>当然你说你数据量大你头铁那我也没办法，毕竟在深度学习中数据量大是可以为所欲为的。</p>
<p>图片来源：</p>
<p><a href="https://blog.csdn.net/willduan1/article/details/53070777" target="_blank" rel="noopener">https://blog.csdn.net/willduan1/article/details/53070777</a></p>
<p>图书 deep learning</p>

  </section>

</article>

<section class="read-more">
           
    
               
            <div class="read-more-item">
                <span class="read-more-item-dim">Newer Post</span>
                <h2 class="post-list__post-title post-title"><a href="/2018/06/02/神经网络实践经验-2/" title="神经网络实践经验(2)">神经网络实践经验(2)</a></h2>
                <p class="excerpt">
                
                前言本人萌新，请多指教
2. 1x1卷积层的作用我们都知道，CNN强于MLP的地方在于其局部连接性减少了过拟合的可能，从而在有限的数据量下可以获取更好的模型。
而CNN是一个基于上下文的网络。对于上下文相关的数据（图像、自然语言等），有着非常理所应当、有理有据的好效果。但是如果filter的大小是1
                &hellip;
                </p>
                <div class="post-list__meta"><time datetime="2018-06-02T09:07:42.000Z" class="post-list__meta--date date">2018-06-02</time> &#8226; <span class="post-list__meta--tags tags">于 
  <a class="tag-link" href="/tags/深度学习/">深度学习</a>, <a class="tag-link" href="/tags/神经网络实践经验/">神经网络实践经验</a>
</span><a class="btn-border-small" href="/2018/06/02/神经网络实践经验-2/">继续阅读</a></div>
                           
            </div>
        
        
        
     
   
   
  
</section>

  

            <footer class="footer">
    <span class="footer__copyright">
        &copy; 2018 kardel - 本站点采用 <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议</a>
       
    </span>
    <span class="footer__copyright">
             - 基于 <a href="http://hexo.io">Hexo</a> 搭建，使用 <a href="https://github.com/monniya/hexo-theme-new-vno ">new-vno</a> 主题，由<a href="https://monniya.com ">@Monniya</a> 修改自 <a href="https://github.com/lenbo-ma/hexo-theme-vno" target="_blank">Vno</a>, 原创出自<a href="http://github.com/onevcat/vno" target="_blank">onevcat</a>
         </span>
       
    
  
         <script type="text/x-mathjax-config">
    MathJax.Hub.Config({"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"], linebreaks: { automatic:true }, EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50) },
        tex2jax: { inlineMath: [ ["$", "$"], ["\\(","\\)"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno",skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']},
        TeX: {  noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } }, Macros: { href: "{}" } },
        messageStyle: "none"
    }); 
    
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
   
</footer>


        </div>
    </div>

     
<script>
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

	ga('create', 'UA-78918255-1', 'auto');
	ga('send', 'pageview');
</script>

    
    <script>
        var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "//hm.baidu.com/hm.js?9cdad07c755fa23f6aced510c6760e87";
            var s = document.getElementsByTagName("script")[0]; 
            s.parentNode.insertBefore(hm, s);
        })();
    </script>



    <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    
    
</body>
</html>
